\chapter{Synchronization without locks}

Synchronization primitives are costly :
\begin{itemize}
  \item spinlocks :
  \begin{itemize}
    \item atomic instruction that locks the memory bus
    \item active wait
  \end{itemize}
  \item semaphore/monitor :
  \begin{itemize}
    \item risk of being unscheduled : cost of switch
    \item entering in the kernel
  \end{itemize}
\end{itemize}

Notice that actual implementation of locks in system such as Linux is a mix between spinlock and unscheduling of the thread.

Other solutions :

\begin{itemize}
  \item algorithmic changes : no more critical sections
  
  Example : Producer/Consumer
  
  \begin{center}
size\\buffer\\head

      \begin{tabular}{l|l}
        Producer & Consumer\\
		\hline
        while(size==N) {} & while(size==0) {}\\
        buffer[(head+size)\%N]= object & result = buffer[head]\\
         & head=(head+1)\%N \\        
        size++ & size -- \\
      \end{tabular}
    \end{center}
  
  
  \begin{itemize}
    \item forget about size
    \item use head and tail
    \item single producer/consumer
    \item SC
  \end{itemize}

So we get :
\begin{center}
tail\\buffer\\head

      \begin{tabular}{l|l}
        Producer & Consumer\\
		\hline
        while((tail+1)\%N==head) {} & while(head==tail) {}\\
        buffer[tail]= object & result = buffer[head]\\
        tail = (tail+1)\%N & head=(head+1)\%N \\        
      \end{tabular}
    \end{center}    

\item take advantage of atomic instructions

Example : 
\begin{verbatim}

Compare_and_Swap(address,old,new)
 if(*address ==old) {
    *address=new;
    return 1;
 }
 else return 0;
\end{verbatim}
can be used to write an atomic stack :

\begin{verbatim}
  void atomic_push(stack* s, int value) {
      item = malloc(sizeof(node));
      item->val = value;
      do {
          item->next = *s;
      } while (compare_and_swap(s, item->next, item);
  }
\end{verbatim}

Similar for atomic\_pop (try to set s to *s-$>$next atomically)

\end{itemize}

Other performance issues include :

\begin{itemize}
  \item locks locality: with non uniform memories or with non uniform caches. $=>$ more elaborate locking structures (hierarchical, or distributed and made coherent)
  \item bottlenecks: if a single lock is used by all the threads $=>$ it's better to separate the work into independant parts and use several locks.
\end{itemize}

