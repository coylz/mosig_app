\documentclass[11pt]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{graphicx}
\usepackage{amsmath}
% Pour colorer une cellule de tableau
\usepackage[table]{xcolor}

% Pour les dessins 
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\tikzset{middlearrow1/.style={
        decoration={markings,
            mark= at position 0.6 with {\arrow{#1}} ,
        },
        postaction={decorate}
    },
	middlearrow2/.style={
        decoration={markings,
            mark= at position 0.4 with {\arrow{#1}} ,
        },
        postaction={decorate}
    }
}
\usetikzlibrary{calc}
\usetikzlibrary{intersections,petri,positioning,arrows}

% Pour les subfig
\usepackage{caption}
\usepackage{subcaption}


% TOC
\addto\captionsfrench{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Table of Contents}%
}

\usepackage[colorlinks=true,linkcolor=blue!50!black,citecolor=blue!30!black,urlcolor=blue!40!red,pdfborder={0 0 0}]{hyperref}

%\usepackage{graphvizzz}

%\usepackage[usenames,dvipsnames]{pstricks}
%\usepackage{epsfig}
%\usepackage{pst-grad} % For gradients
%\usepackage{pst-plot} % For axes

\usepackage{enumitem}

\usepackage{framed}

%%%%%%
% Pour mise-en-forme des fichiers Ada
%
% voir exemple en fin de ce fichier.
%
% ATTENTION, requiert encoding utf-8 (voir 2ième "\lstset" ci-dessous)
 
\usepackage{listings}
%\lstset{
%  morekeywords={abort,abs,accept,access,all,and,array,at,begin,body,
%      case,constant,declare,delay,delta,digits,do,else,elsif,end,entry,
%      exception,exit,for,function,generic,goto,if,in,is,limited,loop,
%      mod,new,not,null,of,or,others,out,package,pragma,private,
%      procedure,raise,range,record,rem,renames,return,reverse,select,
%      separate,subtype,task,terminate,then,type,use,when,while,with,
%      xor,abstract,aliased,protected,requeue,tagged,until,printf},
%  sensitive=f,
%  morecomment=[l]--,
%  morestring=[d]",
%  showstringspaces=false,
%  basicstyle=\tiny\ttfamily,
%  keywordstyle=\bf\tiny,
%  commentstyle=\itshape\tiny,
%  stringstyle=\sf\tiny,
%  extendedchars=true,
%  columns=[c]fixed
%}
\usepackage{color}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\definecolor{myblue}{rgb}{0,0,0.82}
\definecolor{myred}{rgb}{1,0,0}

\lstset{%
  morekeywords={abort,abs,accept,access,all,and,array,at,begin,body,
      case,constant,declare,delay,delta,digits,do,else,elsif,end,entry,
      exception,exit,for,function,generic,goto,if,in,is,limited,loop,
      mod,new,not,null,of,or,others,out,package,pragma,private,
      procedure,raise,range,record,rem,renames,return,reverse,select,
      separate,subtype,task,terminate,then,type,use,when,while,with,
      xor,abstract,aliased,protected,requeue,tagged,until,printf},
  basicstyle=\scriptsize\ttfamily,%
  commentstyle=\color{mygreen}\footnotesize\ttfamily,%
  frameround=trBL,
  frame=single,
  breaklines=true,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny,
  numbersep=10pt,
  language=Java,
  morekeywords={Math},
  keywordstyle=\color{myblue}\bf
}

% CI-DESSOUS: conversion des caractères accentués UTF-8 
% en caractères TeX dans les listings...
\lstset{
  literate=%
  {À}{{\`A}}1 {Â}{{\^A}}1 {Ç}{{\c{C}}}1%
  {à}{{\`a}}1 {â}{{\^a}}1 {ç}{{\c{c}}}1%
  {É}{{\'E}}1 {È}{{\`E}}1 {Ê}{{\^E}}1 {Ë}{{\"E}}1% 
  {é}{{\'e}}1 {è}{{\`e}}1 {ê}{{\^e}}1 {ë}{{\"e}}1%
  {Ï}{{\"I}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1%
  {ï}{{\"i}}1 {î}{{\^i}}1 {ô}{{\^o}}1%
  {Ù}{{\`U}}1 {Û}{{\^U}}1 {Ü}{{\"U}}1%
  {ù}{{\`u}}1 {û}{{\^u}}1 {ü}{{\"u}}1%
}

%%%%%%%%%%
% TAILLE DES PAGES (A4 serré)

\setlength{\parindent}{20pt}
\setlength{\parskip}{1ex}
\setlength{\textwidth}{17cm}
%\setlength{\textwidth}{16cm}
\setlength{\textheight}{23cm}
\setlength{\oddsidemargin}{-.7cm}
\setlength{\evensidemargin}{-.7cm}
\setlength{\topmargin}{-.5in}

%%%%%%%%%%
% EN-TÊTES ET PIED DE PAGES

\pagestyle{fancyplain}
\renewcommand{\headrulewidth}{0pt}
\addtolength{\headheight}{1.6pt}
\addtolength{\headheight}{2.6pt}
\lfoot{}
\cfoot{}


%%%%%%%%%%
% titre du document

\title{Algorithms \\
	\textbf{``Hole Drilling''}}

\author{Thanh Luan, Six Cyril, Vial Loïc \\
			Rouby Thomas, Poupin Pierre\\
			Marriott Richard} 

\date{7\up{th} of November 2014}


\begin{document}

\maketitle
\tableofcontents

\section{Introduction}
\subsection{The Problem}

\subsection{The assumed algorithm}



%%%% DO NOT COPY THIS %%%%%
%%%% WORST CODE EVER %%%%%%
\newcommand{\notalphagraph}[1] {
	\begin{tikzpicture}[scale=0.7]
			\def\n{#1}
			\def\height{6}
			\def\width{6}
			\foreach \x in {0,\width} {
				\foreach \y in {0,2,...,\n} {
					\draw [fill] ($(\x,\y*\height/\n)$) circle [radius=0.1];
					\draw [red,middlearrow1={latex},thick] ($(0,\y*\height/\n)$) -- ($(\width,\y*\height/\n)$);
					\ifnum \y > 0 {
						\draw [red,middlearrow1={latex},thick] ($(\width,\y*\height/\n)$) -- ($(\width,\y*\height/\n - \height/\n)$);
						\draw [red,middlearrow1={latex},thick] ($(\width,\y*\height/\n - \height/\n)$) -- ($(0,\y*\height/\n - \height/\n)$);
						\draw [red,middlearrow1={latex},thick] ($(0,\y*\height/\n - \height/\n)$) -- ($(0,\y*\height/\n - \height/\n - \height/\n)$);
					} \else
					\fi
				}
			}
			\draw [red,middlearrow1={latex},thick] (0,0) -- (\width,0);

			\foreach \x in {0,\width} {
				\foreach \y in {0,...,\n} {
					\draw [fill] ($(\x,\y*\height/\n)$) circle [radius=0.1];
				}
			}
			\draw [blue,middlearrow2={latex},thick] (0.05,\height+0.05) -- (0.05,0.05);
			\draw [blue,middlearrow2={latex},thick] (0.05,0.05) -- (\width+0.05,0.05);
			\draw [blue,middlearrow2={latex},thick] (\width+0.05,0.05) -- (\width+0.05,\height+0.05);
		\end{tikzpicture}
}

\newcommand{\notAlphaGraphOnlyRed}[1] {
	\begin{tikzpicture}[scale=0.85]
			\def\n{#1}
			\def\height{5}
			\def\width{5}
			\foreach \x in {0,\width} {
				\foreach \y in {0,...,\n} {
					\draw [fill] ($(\x,\y*\height/\n)$) circle [radius=0.1];
					\draw [red,middlearrow1={latex},thick] ($(0,\y*\height/\n)$) -- ($(\width,\y*\height/\n)$);
					\ifnum \y > 0 {
						\draw [red,middlearrow1={latex},thick] ($(\width,\y*\height/\n)$) -- ($(0,\y*\height/\n - \height/\n)$);
					} \else
					\fi
				}
			}
		\end{tikzpicture}
}

\newcommand{\NotAlphaGraphOnlyRedTwo}[1] {
	\begin{tikzpicture}[scale=0.7]
			\def\n{#1}
			\def\height{6}
			\def\width{6}
			\foreach \x in {0,\width} {
				\foreach \y in {0,2,...,\n} {
					\draw [fill] ($(\x,\y*\height/\n)$) circle [radius=0.1];
					\draw [red,middlearrow1={latex},thick] ($(0,\y*\height/\n)$) -- ($(\width,\y*\height/\n)$);
					\ifnum \y > 0 {
						\draw [red,middlearrow1={latex},thick] ($(\width,\y*\height/\n)$) -- ($(\width,\y*\height/\n - \height/\n)$);
						\draw [red,middlearrow1={latex},thick] ($(\width,\y*\height/\n - \height/\n)$) -- ($(0,\y*\height/\n - \height/\n)$);
						\draw [red,middlearrow1={latex},thick] ($(0,\y*\height/\n - \height/\n)$) -- ($(0,\y*\height/\n - \height/\n - \height/\n)$);
					} \else
					\fi
				}
			}
			\draw [red,middlearrow1={latex},thick] (0,0) -- (\width,0);

			\foreach \x in {0,\width} {
				\foreach \y in {0,...,\n} {
					\draw [fill] ($(\x,\y*\height/\n)$) circle [radius=0.1];
				}
			}
		\end{tikzpicture}
}

\section{Proof that the currently used algorithm is not an $\alpha$-approximation}
%%% THIS ONE IS NOT THE BEST TOP TO BOTTOM
We do not have many informations about the current algorithm. We only know that it starts from the top left corner of the board, and that
it pierces holes from top to bottom.

Many algorithms could do that, but as we can see on the
figures \ref{fig:naive} and \ref{fig:bestnaive}, some are better than others. We will use the latter one.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\notAlphaGraphOnlyRed{4}
		\caption{Path that we would obtain with a naive algorithm}
		\label{fig:naive}
	\end{subfigure}
	\hspace{0.05\textwidth}
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\NotAlphaGraphOnlyRedTwo{4}
		\caption{Path that we would obtain with the best naive algorithm}
		\label{fig:bestnaive}
	\end{subfigure}
\end{figure}

We may now wonder whether this algorithm is an $\alpha$-approximation or not. If this was the case, we would be able to find $\alpha$ such that
\[
	\forall I \in \mathcal{I}, \; \frac{{L}_{Algorithm}}{{L}_{Optimal}} \leq \alpha
\]

Let's look at the figure \ref{fig:counter-example}. The optimal solution is drawn in \textcolor{myblue}{blue}, while the algorithm's one
is in \textcolor{myred}{red}. We can see that, in such a configuration, the number of points to drill doesn't change the length of the
optimal path. However, the more points we have, the longer the red path will be. With an infinite number of points, the red path
is theoretically infinite. Which means that it is impossible to define $\alpha$ for such an algorithm. Besides, this is the case for the best
naive algorithm, which means it will be for any naive algorithm.

Hence, the algorithm is \textbf{not} an $\alpha$-approximation.


\begin{figure}
        \centering
        \begin{subfigure}[b]{0.2\textwidth}
				\notalphagraph{2}
        \end{subfigure}
		\hfill
        \begin{subfigure}[b]{0.2\textwidth}
				\notalphagraph{6}
        \end{subfigure}
		\hfill
        \begin{subfigure}[b]{0.2\textwidth}
				\notalphagraph{14}
        \end{subfigure}
        \caption{Different paths depending on the number of to-be-drilled points}
		\label{fig:counter-example}
\end{figure}


\section{A Greedy Algorithm (Pac-Man)}
\subsection{Algorithm itself}
It consists in taking at each iteration the shortest path to an unvisited node.

\begin{lstlisting}
/**
 * Let's suppose :
 *	the starting point is (x0, y0)
 *	there are N holes to drill, their positions denoted by (xi, yi) 
 *	There is no need to go back to the starting point.
 *	The starting point is modelised by a node
 */

struct Node is:
	int x, y
	bool visited

holes : array of Nodes

/* The head is initially at (x0, y0) */
hole_drilling() is:
	current = holes[0] // start with the starting point
	nb_drilled = 0
	while (nb_drilled != len(holes)-1) do:
		current.visited = true
		min_distance = +infinite
		for i in 0..len(holes) do:
			if holes[i].visited:
				continue

			d = distance(current, holes[i])
			if d < min_distance:
				min_distance = d
				next_node = holes[i]
		done

		move head from current to next_node
		current = next_node
		drill current
		nb_drilled++
	done
end
\end{lstlisting}

\subsection{Proof that Pac-Man is not optimal}
Let's consider the following example :\\
\textbf{Some figure needed}\\

The distance obtained with the Greedy algorithm (in red) would be :
$d_{greedy} = Nd + \sqrt{N^2 d^2 + h^2}$.\\
On the other hand, another path (in blue) would give the distance :
$d_{path} = h + \sqrt{h^2 + d^2} + (N-1) d$\\
The difference of the two is :
$d_{greedy} - d_{path} = d + \sqrt{N^2 d^2 + h^2} - h - \sqrt{h^2 + d^2}$\\

Let's take the following values : $N = 10$, $d = 1$, and $h = 3$.
Then the value of the difference is : $d_{greedy} - d_{path} \simeq 5.28 > 0$, 
so there exists a path shorter than the greedy path.
Thus, Pac-Man is not optimal.

\section{Minimal spanning tree algorithm}

\subsection{The Beautiful Algorithm}

\subsubsection{Basics}
We cannot prove that the previous greedy algorithm is a two-approximation or not. Therefore, we consider another way of solving the problem, based on a minimum-spanning tree. With this method, we will be able to have a two-approximation and then assure that our solution is at most twice the optimal.
\subsubsection{How does it works}

The minimum spanning tree is the tree which covers all nodes of the graph and by minimising the total weigth of the tree.
We have two differents, greedy algorithms that allow us to compute the MST : Prim's algorithm and Kruskal's algorithm. We chose Prim's Algorithm since it is easier to implement, and has the same complexity as Kruskal's, provided we choose the right structures to store the graph and the tree.

Then, We have our MST : Since it is a tree, we can decide that the closest vertex to the drill is the tree's root.
Now, we can compute a Depth-First Search in this tree, where we will visit first the most left child, then the second most... .
During this search, we mark the nodes as visited and we add their coordinates in a linked list. If we visit a node twice (when we reach a leaf and we go back to the parent for instance), the node is marked, so we don't add the node in the list twice.

Finally, Since all the nodes will be visited with the Depth First Search, all holes will be added to the linked list, and the Drill will just have to follow the coordinates inside the list.

\subsubsection{Proof that it is a 2-approximation}

Consider first a basic solution, easier than our previous beautiful algorithm:
We no longer mark the nodes, we simply compute the path by following which nodes are visited by the Depth First Search. Each time you visit a leaf, you no longer go to the next marked node (the next leaf if it exists), but you go back to the parent node and then you go to the first child.
We follow the stack of recursive calls in the Depth First Search basically.

We will show that this algorithm is a 2-approximation, to proove that the beautiful algorithm is also a 2-approximation, since it is better than the basic one.

Let's first show that the optimal solution is greater than the sum of all the edges' lengths of the MST :

Consider the optimal solution : It must go through all the nodes, so it is an hamiltonian path. But it is also a spanning tree, since it covers all the nodes of the graph.
But we computed the minimal spanning tree, so obviously, the total weigth of the optimal solution is greater than the weight of the MST.

Let's now proove that our basic solution is not greater than twice the optimal solution, by showing that it is not greater than twice the weight of the MST : we will get the final result thanks to the previous point.

The idea of our basic solution is to compute a Depth First Search in the MST :
In general, to visit all nodes of a tree, parent nodes will have to be visited more that once: once for each child node. This means that the parent-child edges will each have to be traversed twice: once on the way down and once on the way back to the parent node (unless you start at or below the child node).

In the worst case, you visit all the edges of the MST twice. so  our solution has a upper bound equals to twice the weight of the MST.
Since the weight of the MST is lower than the optimal solution, we have the following result :

The basic algorithm is a 2-approximation of the optimal solution.


Let's now show that our beautiful algorithm has a lower cost than the basic one :

Instead of going up to the parent node and going to the next child as the basic algorithm does, the beautiful one goes directly to the following unvisited node.
Thanks to the triangular inequality (provided we use the euclidian distance in a euclidian space, which is the case...), we know that the path taken by the beautiful algorithm is shorter than the one taken by the basic one.
"the shortest path between two points is following the line which goest through those two points".

So, the beautiful algorithm is better than a 2-approximation algorithm, so it is also a 2-approximation of the optimal solution.




\subsection{Luan's algorithm}

\subsubsection{Proof that Luan's algorithm is a 2-approximation}


\subsection{Re-visiting the greedy algorithm}
% argue that Lua's algorithm is the same as the greedy algorithm
% and that, therefore, the greedy algo is a 2-approx

% propose the new greedy algo


\section{Conclusion}



\subsection{Computing the Minimum Spanning Tree}


\subsection{Depth First Search of the tree}




\subsection{RICHARD}

The optimal solution:

The weights of the edges of our graph are distances. For any 3 nodes there is 
always a direct route between the 2\up{nd} and 3\up{rd} nodes that is inferior or equal to the path 2-1-3. E.g. on figures
\ref{fig:gencase} and \ref{fig:worstcase}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}[auto,main node/.style={circle,draw=blue!80,minimum size=0.4cm,inner sep=0pt,thick}]
			\node[main node,label=left:2] (first) at (0,3.5) { };
			\node[main node,label=right:3] (second) at (4,3.5) { }
			edge node [above] {c} (first);
			\node[main node,label=below:1] (third) at (2,0) { }
			edge node [left] {a} (first) 	
			edge node [right] {b} (second) ;
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		$
		c^2 = a^2 + b^2 -2ab\cos(\theta) < (a + b)^2
		$
		\vspace{2cm}
	\end{subfigure}
	\caption{General Case}
	\label{fig:gencase}
\end{figure}


\begin{figure}[ht]
	\centering
	\begin{tabular}{m{7cm}m{4cm}}
		\begin{tikzpicture}[auto,main node/.style={circle,draw=blue!80,minimum size=0.4cm,inner sep=0pt,thick}]
			\node[main node,label=left:2] (first) at (0,0) { };
			\node[main node,label=below:3] (second) at (2,0) { }
			edge node [above] {a} (first);
			\node[main node,label=right:1] (third) at (4,0) { }
			edge node [above] {b} (second) ;
		\end{tikzpicture}
		&
		$c = a + b$
	\end{tabular}
		\caption{Worst Case}
	\label{fig:worstcase}
\end{figure}

Therefore, the optimal route will never use edges twice.
(For the worst case of aligned nodes, it could, but we may as well just propose a 
direct path be 2 and 3.) The optimal route will use the (n-1) shortest edges to visit n nodes. \label{ref1}

\subsubsection{Proof that a pure MST-based solution is a 2-approximation}
In general, to visit all nodes of a tree, parent nodes will have to be visited more that once: once for each child node. This means that the parent-child edges will each have to be traversed twice: once on the way down and once on the way back to the parent node (unless you start at or below the child node).

\begin{enumerate}[label=•]
	\item The best case is to start at a leaf node such that the first branch need only be traversed once - on the way up. (The final branch will also only need to be traversed once - on the way down.)

	\item The worst case is to start at the root node. In this case, all branches will need to be traversed twice except for the final branch.
\end{enumerate}

For a tree where each node has at least two children, the final branch will only be of length one. In this case, starting at the root node will lead to a depth-wise search of the tree taking ($2n-1$) moves.

From \ref{ref1} we know that, in the optimal case, visiting each node would take ($n-1$) moves.

Therefore
\begin{equation}
	\alpha = \frac{C}{C^*} \leq \frac{2n-1}{n-1} = 2 + \frac{1}{n-1} \underset{n\to\infty}{\longrightarrow} 2
	\label{eq:1}
\end{equation}



\subsubsection{FOR CYRIL}

\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\begin{tikzpicture}[auto,
							main node/.style={circle,draw=blue!80,minimum size=0.4cm,inner sep=0pt,thick},
							start node/.style={circle,draw=red!80,minimum size=0.4cm,inner sep=0pt,thick}]
			\node[main node] (h) at (0,0) { };
			\node[start node,label=left:Start] (n1) at (0,2) { };
			\node[main node] (n2) at (1,2) { }
			edge node {d} (n1);
			\node[main node] (n3) at (2,2) { }
			edge node {} (n2);
			\node[main node] (n4) at (3,2) { }
			edge node {} (n3);
			\node[main node] (n5) at (4,2) { }
			edge node {} (n4);
			\node[main node] (n6) at (5,2) { }
			edge node {} (n5)
			edge node {} (h);
		\end{tikzpicture}
	\end{subfigure}
	\hspace{0.05\textwidth}
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\begin{tikzpicture}[auto,
							main node/.style={circle,draw=blue!80,minimum size=0.4cm,inner sep=0pt,thick},
							start node/.style={circle,draw=red!80,minimum size=0.4cm,inner sep=0pt,thick}]
			\node[main node] (h) at (0,0) { };
			\node[start node,label=left:Start] (n1) at (0,2) { }
			edge node [left] {h} (h);
			\node[main node] (n2) at (1,2) { }
			edge node {} (h);
			\node[main node] (n3) at (2,2) { }
			edge node {d} (n2);
			\node[main node] (n4) at (3,2) { }
			edge node {} (n3);
			\node[main node] (n5) at (4,2) { }
			edge node {} (n4);
			\node[main node] (n6) at (5,2) { }
			edge node {} (n5);
		\end{tikzpicture}
	\end{subfigure}
\end{figure}

\end{document}
